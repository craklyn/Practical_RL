{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "This notebook will guide you through implementation of vanilla Q-learning algorithm.\n",
    "\n",
    "You need to implement QLearningAgent (follow instructions for each method) and use it on a number of tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n",
      "env: DISPLAY=:1\n"
     ]
    }
   ],
   "source": [
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1\n",
    "        \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting qlearning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qlearning.py\n",
    "from collections import defaultdict\n",
    "import random, math\n",
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on http://inst.eecs.berkeley.edu/~cs188/sp09/pacman.html\n",
    "        Instance variables you have access to\n",
    "          - self.epsilon (exploration prob)\n",
    "          - self.alpha (learning rate)\n",
    "          - self.discount (discount rate aka gamma)\n",
    "\n",
    "        Functions you should use\n",
    "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
    "            which returns legal actions for a state\n",
    "          - self.get_qvalue(state,action)\n",
    "            which returns Q(state,action)\n",
    "          - self.set_qvalue(state,action,value)\n",
    "            which sets Q(state,action) := value\n",
    "\n",
    "        !!!Important!!!\n",
    "        Note: please avoid using self._qValues directly. \n",
    "            There's a special self.get_qvalue/set_qvalue for that.\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self,state,action,value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #---------------------START OF YOUR CODE---------------------#\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        Compute your agent's estimate of V(s) using current q-values\n",
    "        V(s) = max_over_action Q(state,action) over possible actions.\n",
    "        Note: please take into account that q-values can be negative.\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "        value = max([self.get_qvalue(state, a) for a in possible_actions])\n",
    "\n",
    "        return value\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        You should do your Q-Value update here:\n",
    "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "        \"\"\"\n",
    "\n",
    "        #agent parameters\n",
    "        gamma = self.discount\n",
    "        learning_rate = self.alpha\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "        qval = (1 - learning_rate) * self.get_qvalue(state, action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
    "        \n",
    "        self.set_qvalue(state, action, qval)\n",
    "\n",
    "    \n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "        best_value = self.get_value(state)\n",
    "        \n",
    "        best_actions = [a for a in possible_actions if self.get_qvalue(state, a) == best_value]\n",
    "        best_action = random.sample(best_actions, k=1)[0]\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the action to take in the current state, including exploration.  \n",
    "        With probability self.epsilon, we should take a random action.\n",
    "            otherwise - the best policy action (self.getPolicy).\n",
    "        \n",
    "        Note: To pick randomly from a list, use random.choice(list). \n",
    "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
    "              and compare it with your probability\n",
    "        \"\"\"\n",
    "\n",
    "        # Pick Action\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        #agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "        if self.epsilon > random.random():\n",
    "            chosen_action = random.sample(possible_actions, k=1)[0]\n",
    "        else:\n",
    "            chosen_action = self.get_best_action(state)            \n",
    "        \n",
    "        return chosen_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it on taxi\n",
    "\n",
    "Here we use the qlearning agent on taxi env from openai gym.\n",
    "You will need to insert a few agent functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlearning import QLearningAgent\n",
    "\n",
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env,agent,t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function should \n",
    "    - run a full game, actions given by agent's e-greedy policy\n",
    "    - train agent using agent.update(...) whenever it is possible\n",
    "    - return total reward\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s.\n",
    "        a = agent.get_action(s) # <YOUR CODE>\n",
    "        \n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        # train (update) agent for state s\n",
    "        agent.update(s, a, r, next_s) #<YOUR CODE HERE>\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done: break\n",
    "        \n",
    "    return total_reward\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 2.9191091959171894e-05 mean reward = 6.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    agent.epsilon *= 0.99\n",
    "    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera I: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_rewards1 = rewards.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Binarized state spaces\n",
    "\n",
    "Use agent to train efficiently on CartPole-v0.\n",
    "This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
    "\n",
    "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
    "\n",
    "The tricky part is to get the n_digits right for each state to train effectively.\n",
    "\n",
    "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"first state:%s\" % (env.reset()))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a few games\n",
    "\n",
    "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    plt.hist(all_states[:, obs_i], bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "class Binarizer(ObservationWrapper):\n",
    "    \n",
    "    def _observation(self, state):    \n",
    "        \n",
    "        #state = <round state to some amount digits.>\n",
    "        #hint: you can do that with round(x,n_digits)\n",
    "        #you will need to pick a different n_digits for each dimension\n",
    "\n",
    "        return tuple(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Binarizer(gym.make(\"CartPole-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    \n",
    "    plt.hist(all_states[:,obs_i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn binarized policy\n",
    "\n",
    "Now let's train a policy that uses binarized state space.\n",
    "\n",
    "__Tips:__ \n",
    "* If your binarization is too coarse, your agent may fail to find optimal policy. In that case, change binarization. \n",
    "* If your binarization is too fine-grained, your agent will take much longer than 1000 steps to converge. You can either increase number of iterations and decrease epsilon decay or change binarization.\n",
    "* Having 10^3 ~ 10^4 distinct states is recommended (`len(QLearningAgent._qvalues)`), but not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions=lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env,agent))   \n",
    "    \n",
    "    #OPTIONAL YOUR CODE: adjust epsilon\n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submit to Coursera II: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_rewards2 = rewards.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from submit import submit_qlearning\n",
    "submit_qlearning(submit_rewards1, submit_rewards2, <EMAIL>, <TOKEN>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
